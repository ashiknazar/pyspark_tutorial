{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Person_1</td>\n",
       "      <td>20</td>\n",
       "      <td>City_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Person_2</td>\n",
       "      <td>21</td>\n",
       "      <td>City_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Person_3</td>\n",
       "      <td>22</td>\n",
       "      <td>City_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Person_4</td>\n",
       "      <td>23</td>\n",
       "      <td>City_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Person_5</td>\n",
       "      <td>24</td>\n",
       "      <td>City_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Person_6</td>\n",
       "      <td>25</td>\n",
       "      <td>City_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Person_7</td>\n",
       "      <td>26</td>\n",
       "      <td>City_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Person_8</td>\n",
       "      <td>27</td>\n",
       "      <td>City_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Person_9</td>\n",
       "      <td>28</td>\n",
       "      <td>City_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Person_10</td>\n",
       "      <td>29</td>\n",
       "      <td>City_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Person_11</td>\n",
       "      <td>30</td>\n",
       "      <td>City_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Person_12</td>\n",
       "      <td>31</td>\n",
       "      <td>City_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Person_13</td>\n",
       "      <td>32</td>\n",
       "      <td>City_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Person_14</td>\n",
       "      <td>33</td>\n",
       "      <td>City_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Person_15</td>\n",
       "      <td>34</td>\n",
       "      <td>City_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Person_16</td>\n",
       "      <td>35</td>\n",
       "      <td>City_16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Person_17</td>\n",
       "      <td>36</td>\n",
       "      <td>City_17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Person_18</td>\n",
       "      <td>37</td>\n",
       "      <td>City_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Person_19</td>\n",
       "      <td>38</td>\n",
       "      <td>City_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Person_20</td>\n",
       "      <td>39</td>\n",
       "      <td>City_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Person_21</td>\n",
       "      <td>40</td>\n",
       "      <td>City_21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Person_22</td>\n",
       "      <td>41</td>\n",
       "      <td>City_22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Person_23</td>\n",
       "      <td>42</td>\n",
       "      <td>City_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Person_24</td>\n",
       "      <td>43</td>\n",
       "      <td>City_24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>44</td>\n",
       "      <td>City_25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Person_26</td>\n",
       "      <td>45</td>\n",
       "      <td>City_26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Person_27</td>\n",
       "      <td>46</td>\n",
       "      <td>City_27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Person_28</td>\n",
       "      <td>47</td>\n",
       "      <td>City_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Person_29</td>\n",
       "      <td>48</td>\n",
       "      <td>City_29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Person_30</td>\n",
       "      <td>49</td>\n",
       "      <td>City_30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name  Age     City\n",
       "0    Person_1   20   City_1\n",
       "1    Person_2   21   City_2\n",
       "2    Person_3   22   City_3\n",
       "3    Person_4   23   City_4\n",
       "4    Person_5   24   City_5\n",
       "5    Person_6   25   City_6\n",
       "6    Person_7   26   City_7\n",
       "7    Person_8   27   City_8\n",
       "8    Person_9   28   City_9\n",
       "9   Person_10   29  City_10\n",
       "10  Person_11   30  City_11\n",
       "11  Person_12   31  City_12\n",
       "12  Person_13   32  City_13\n",
       "13  Person_14   33  City_14\n",
       "14  Person_15   34  City_15\n",
       "15  Person_16   35  City_16\n",
       "16  Person_17   36  City_17\n",
       "17  Person_18   37  City_18\n",
       "18  Person_19   38  City_19\n",
       "19  Person_20   39  City_20\n",
       "20  Person_21   40  City_21\n",
       "21  Person_22   41  City_22\n",
       "22  Person_23   42  City_23\n",
       "23  Person_24   43  City_24\n",
       "24  Person_25   44  City_25\n",
       "25  Person_26   45  City_26\n",
       "26  Person_27   46  City_27\n",
       "27  Person_28   47  City_28\n",
       "28  Person_29   48  City_29\n",
       "29  Person_30   49  City_30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ashik:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1f58b6bc4f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_py=spark.read.csv('new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+-------+\n",
      "|      _c0|_c1|    _c2|\n",
      "+---------+---+-------+\n",
      "|     Name|Age|   City|\n",
      "| Person_1| 20| City_1|\n",
      "| Person_2| 21| City_2|\n",
      "| Person_3| 22| City_3|\n",
      "| Person_4| 23| City_4|\n",
      "| Person_5| 24| City_5|\n",
      "| Person_6| 25| City_6|\n",
      "| Person_7| 26| City_7|\n",
      "| Person_8| 27| City_8|\n",
      "| Person_9| 28| City_9|\n",
      "|Person_10| 29|City_10|\n",
      "|Person_11| 30|City_11|\n",
      "|Person_12| 31|City_12|\n",
      "|Person_13| 32|City_13|\n",
      "|Person_14| 33|City_14|\n",
      "|Person_15| 34|City_15|\n",
      "|Person_16| 35|City_16|\n",
      "|Person_17| 36|City_17|\n",
      "|Person_18| 37|City_18|\n",
      "|Person_19| 38|City_19|\n",
      "+---------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_py.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+-------+\n",
      "|     Name|Age|   City|\n",
      "+---------+---+-------+\n",
      "| Person_1| 20| City_1|\n",
      "| Person_2| 21| City_2|\n",
      "| Person_3| 22| City_3|\n",
      "| Person_4| 23| City_4|\n",
      "| Person_5| 24| City_5|\n",
      "| Person_6| 25| City_6|\n",
      "| Person_7| 26| City_7|\n",
      "| Person_8| 27| City_8|\n",
      "| Person_9| 28| City_9|\n",
      "|Person_10| 29|City_10|\n",
      "|Person_11| 30|City_11|\n",
      "|Person_12| 31|City_12|\n",
      "|Person_13| 32|City_13|\n",
      "|Person_14| 33|City_14|\n",
      "|Person_15| 34|City_15|\n",
      "|Person_16| 35|City_16|\n",
      "|Person_17| 36|City_17|\n",
      "|Person_18| 37|City_18|\n",
      "|Person_19| 38|City_19|\n",
      "|Person_20| 39|City_20|\n",
      "+---------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfspark=spark.read.option('header','true').csv('new.csv').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspark=spark.read.option('header','true').csv('new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dfspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Name='Person_1', Age='20', City='City_1')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfspark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfspark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pyspark datasframe\n",
    "- reading dataset\n",
    "- checking datatypes of column\n",
    "- selecting columns and indexing\n",
    "- check describe option similar to pandas\n",
    "- adding columns\n",
    "- dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('DataFrame').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark=spark.read.option('header','true').csv('sal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- experience: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- experience: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark=spark.read.option('header','true').csv('sal.csv',inferSchema=True)\n",
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+\n",
      "|name|age|experience|\n",
      "+----+---+----------+\n",
      "|ajas| 23|     1 yrs|\n",
      "|arun| 24|     3 yrs|\n",
      "|jais| 27|     7 yrs|\n",
      "+----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spard=spark.read.csv('sal.csv',header=True,inferSchema=True)\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'age', 'experience']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='ajas', age=23, experience='1 yrs'),\n",
       " Row(name='arun', age=24, experience='3 yrs'),\n",
       " Row(name='jais', age=27, experience='7 yrs')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+\n",
      "|name|age|experience|\n",
      "+----+---+----------+\n",
      "|ajas| 23|     1 yrs|\n",
      "|arun| 24|     3 yrs|\n",
      "|jais| 27|     7 yrs|\n",
      "+----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|name|\n",
      "+----+\n",
      "|ajas|\n",
      "|arun|\n",
      "|jais|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select('name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "|ajas| 23|\n",
      "|arun| 24|\n",
      "|jais| 27|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select(['name','age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'name'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 'string'), ('age', 'int'), ('experience', 'string')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, name: string, age: string, experience: string]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------------------+----------+\n",
      "|summary|name|               age|experience|\n",
      "+-------+----+------------------+----------+\n",
      "|  count|   3|                 3|         3|\n",
      "|   mean|NULL|24.666666666666668|      NULL|\n",
      "| stddev|NULL|2.0816659994661326|      NULL|\n",
      "|    min|ajas|                23|     1 yrs|\n",
      "|    max|jais|                27|     7 yrs|\n",
      "+-------+----+------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### adding and removing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.withColumn('fullname', concat(df_spark['name'], lit('.sr')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+--------+\n",
      "|name|age|experience|fullname|\n",
      "+----+---+----------+--------+\n",
      "|ajas| 23|     1 yrs| ajas.sr|\n",
      "|arun| 24|     3 yrs| arun.sr|\n",
      "|jais| 27|     7 yrs| jais.sr|\n",
      "+----+---+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'age', 'experience', 'fullname']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+\n",
      "|name|age|experience|\n",
      "+----+---+----------+\n",
      "|ajas| 23|     1 yrs|\n",
      "|arun| 24|     3 yrs|\n",
      "|jais| 27|     7 yrs|\n",
      "+----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_spark.drop('fullname').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+--------+\n",
      "|name|age|experience|fullname|\n",
      "+----+---+----------+--------+\n",
      "|ajas| 23|     1 yrs| ajas.sr|\n",
      "|arun| 24|     3 yrs| arun.sr|\n",
      "|jais| 27|     7 yrs| jais.sr|\n",
      "+----+---+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+-------+\n",
      "|name|age|experience| father|\n",
      "+----+---+----------+-------+\n",
      "|ajas| 23|     1 yrs|ajas.sr|\n",
      "|arun| 24|     3 yrs|arun.sr|\n",
      "|jais| 27|     7 yrs|jais.sr|\n",
      "+----+---+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.withColumnRenamed('fullname','father').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- droping columns\n",
    "- dropping rows\n",
    "- various parameters in dropping functionalities\n",
    "- handling missing values by mean,median,mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_sp=spark.read.csv('exp.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----+----+\n",
      "|name| age|  exp| sal|\n",
      "+----+----+-----+----+\n",
      "|   a|  23|1 yrs|2000|\n",
      "|   b|NULL|2 yrs|3000|\n",
      "|   c|  28|3 yrs|3900|\n",
      "|NULL|  23|4 yrs|2000|\n",
      "+----+----+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "py_sp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----+\n",
      "|name| age|  exp|\n",
      "+----+----+-----+\n",
      "|   a|  23|1 yrs|\n",
      "|   b|NULL|2 yrs|\n",
      "|   c|  28|3 yrs|\n",
      "|NULL|  23|4 yrs|\n",
      "+----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "py_sp.drop('sal').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----+----+\n",
      "|name|age|  exp| sal|\n",
      "+----+---+-----+----+\n",
      "|   a| 23|1 yrs|2000|\n",
      "|   c| 28|3 yrs|3900|\n",
      "+----+---+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "py_sp.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----+----+\n",
      "|name| age|  exp| sal|\n",
      "+----+----+-----+----+\n",
      "|   a|  23|1 yrs|2000|\n",
      "|   b|NULL|2 yrs|3000|\n",
      "|   c|  28|3 yrs|3900|\n",
      "|NULL|  23|4 yrs|2000|\n",
      "+----+----+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#any==how\n",
    "py_sp.na.drop(how=\"all\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----+----+\n",
      "|name| age|  exp| sal|\n",
      "+----+----+-----+----+\n",
      "|   a|  23|1 yrs|2000|\n",
      "|   b|NULL|2 yrs|3000|\n",
      "|   c|  28|3 yrs|3900|\n",
      "|NULL|  23|4 yrs|2000|\n",
      "+----+----+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "py_sp.na.drop(how=\"any\",thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----+----+\n",
      "|name|age|  exp| sal|\n",
      "+----+---+-----+----+\n",
      "|   a| 23|1 yrs|2000|\n",
      "|   c| 28|3 yrs|3900|\n",
      "+----+---+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "py_sp.na.drop(how=\"any\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----+----+\n",
      "|name|age|  exp| sal|\n",
      "+----+---+-----+----+\n",
      "|   a| 23|1 yrs|2000|\n",
      "|   c| 28|3 yrs|3900|\n",
      "|NULL| 23|4 yrs|2000|\n",
      "+----+---+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "py_sp.na.drop(how=\"any\",subset=['age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+-----+----+\n",
      "|          name| age|  exp| sal|\n",
      "+--------------+----+-----+----+\n",
      "|             a|  23|1 yrs|2000|\n",
      "|             b|NULL|2 yrs|3000|\n",
      "|             c|  28|3 yrs|3900|\n",
      "|Missing Values|  23|4 yrs|2000|\n",
      "+--------------+----+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "py_sp.na.fill('Missing Values').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----+----+\n",
      "|name|age|  exp| sal|\n",
      "+----+---+-----+----+\n",
      "|   a| 23|1 yrs|2000|\n",
      "|   b|  4|2 yrs|3000|\n",
      "|   c| 28|3 yrs|3900|\n",
      "|NULL| 23|4 yrs|2000|\n",
      "+----+---+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "py_sp.na.fill(4,'age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#py_sp.na.fill(4,['age','income']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "imputer=Imputer(\n",
    "    inputCols=['age','sal'],\n",
    "    outputCols=[\"{}_imputed\".format(c) for c in ['age','sal']]\n",
    ").setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----+----+-----------+-----------+\n",
      "|name| age|  exp| sal|age_imputed|sal_imputed|\n",
      "+----+----+-----+----+-----------+-----------+\n",
      "|   a|  23|1 yrs|2000|         23|       2000|\n",
      "|   b|NULL|2 yrs|3000|         24|       3000|\n",
      "|   c|  28|3 yrs|3900|         28|       3900|\n",
      "|NULL|  23|4 yrs|2000|         23|       2000|\n",
      "+----+----+-----+----+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(py_sp).transform(py_sp).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "imputer=Imputer(\n",
    "    inputCols=['age','sal'],\n",
    "    outputCols=[\"{}_imputed\".format(c) for c in ['age','sal']]\n",
    ").setStrategy(\"median\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- filter operations\n",
    "- & , | , == \n",
    "- ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('dataframe').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv('sal.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+\n",
      "|name|age|experience|\n",
      "+----+---+----------+\n",
      "|ajas| 23|     1 yrs|\n",
      "|arun| 24|     3 yrs|\n",
      "|jais| 27|     7 yrs|\n",
      "+----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+\n",
      "|name|age|experience|\n",
      "+----+---+----------+\n",
      "|ajas| 23|     1 yrs|\n",
      "|arun| 24|     3 yrs|\n",
      "+----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"age<=25\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "|ajas| 23|\n",
      "|arun| 24|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"age<=25\").select(['name','age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+\n",
      "|name|age|experience|\n",
      "+----+---+----------+\n",
      "|ajas| 23|     1 yrs|\n",
      "|arun| 24|     3 yrs|\n",
      "+----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['age']<=26).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+\n",
      "|name|age|experience|\n",
      "+----+---+----------+\n",
      "|ajas| 23|     1 yrs|\n",
      "+----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df['age']<=26)&(df['name']=='ajas') ).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv('employee_data.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+------+-----------------+\n",
      "|       Name|Age|Salary|      Designation|\n",
      "+-----------+---+------+-----------------+\n",
      "| Employee_1| 49|122891|Software Engineer|\n",
      "| Employee_2| 42| 77224|  Sales Executive|\n",
      "| Employee_3| 27|136994|          Manager|\n",
      "| Employee_4| 57| 74175|          Analyst|\n",
      "| Employee_5| 38|138765|          Manager|\n",
      "| Employee_6| 29| 64244|Software Engineer|\n",
      "| Employee_7| 46| 51236|               HR|\n",
      "| Employee_8| 45|121571|Software Engineer|\n",
      "| Employee_9| 34| 37405|          Analyst|\n",
      "|Employee_10| 33| 50522|Software Engineer|\n",
      "|Employee_11| 55|110087|          Analyst|\n",
      "|Employee_12| 47|125566|  Sales Executive|\n",
      "|Employee_13| 57| 71867|          Manager|\n",
      "|Employee_14| 54| 93453|          Manager|\n",
      "|Employee_15| 46| 95744|               HR|\n",
      "|Employee_16| 58| 66638|  Sales Executive|\n",
      "|Employee_17| 51| 68570|          Manager|\n",
      "|Employee_18| 55| 79381|          Analyst|\n",
      "|Employee_19| 39|129697|               HR|\n",
      "|Employee_20| 35| 37871|               HR|\n",
      "+-----------+---+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      " |-- Designation: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+-----------+\n",
      "|      Designation|sum(Age)|sum(Salary)|\n",
      "+-----------------+--------+-----------+\n",
      "|  Sales Executive|     147|     269428|\n",
      "|               HR|     166|     314548|\n",
      "|          Analyst|     201|     301048|\n",
      "|          Manager|     227|     509649|\n",
      "|Software Engineer|     156|     359228|\n",
      "+-----------------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Designation').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|      Designation|count|\n",
      "+-----------------+-----+\n",
      "|  Sales Executive|    3|\n",
      "|               HR|    4|\n",
      "|          Analyst|    4|\n",
      "|          Manager|    5|\n",
      "|Software Engineer|    4|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Designation').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(Salary)|\n",
      "+-----------+\n",
      "|    1753901|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({'Salary':'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+-----------+\n",
      "|      Designation|min(Age)|min(Salary)|\n",
      "+-----------------+--------+-----------+\n",
      "|  Sales Executive|      42|      66638|\n",
      "|               HR|      35|      37871|\n",
      "|          Analyst|      34|      37405|\n",
      "|          Manager|      27|      68570|\n",
      "|Software Engineer|      29|      50522|\n",
      "+-----------------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Designation').min().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('dataframe').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv('salary.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- designation: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- experience: integer (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "featureassembler=VectorAssembler(inputCols=[\"age\",\"experience\"],outputCol=\"Indep features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=featureassembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+---+----------+------+--------------+\n",
      "|           name|         designation|age|experience|salary|Indep features|\n",
      "+---------------+--------------------+---+----------+------+--------------+\n",
      "|       John Doe|   Software Engineer| 28|         5| 70000|    [28.0,5.0]|\n",
      "|     Jane Smith|      Data Scientist| 32|         7| 90000|    [32.0,7.0]|\n",
      "|  Emily Johnson|     Project Manager| 35|        10|110000|   [35.0,10.0]|\n",
      "|  Michael Brown|    Senior Developer| 30|         8| 85000|    [30.0,8.0]|\n",
      "|    Sarah Davis|         UX Designer| 27|         4| 65000|    [27.0,4.0]|\n",
      "|   Chris Wilson|     DevOps Engineer| 29|         6| 75000|    [29.0,6.0]|\n",
      "|Patricia Miller|          HR Manager| 40|        15| 95000|   [40.0,15.0]|\n",
      "| James Anderson|System Administrator| 33|         8| 80000|    [33.0,8.0]|\n",
      "|   Linda Thomas|    Business Analyst| 36|        12| 92000|   [36.0,12.0]|\n",
      "|     Robert Lee|     Quality Analyst| 31|         7| 78000|    [31.0,7.0]|\n",
      "| Barbara Harris|      Technical Lead| 38|        14|100000|   [38.0,14.0]|\n",
      "|    David Clark|              Intern| 22|         0| 30000|    [22.0,0.0]|\n",
      "| Jessica Walker|   Marketing Manager| 34|        10| 88000|   [34.0,10.0]|\n",
      "|    Daniel Hall|  Frontend Developer| 26|         3| 62000|    [26.0,3.0]|\n",
      "|    Susan Allen|   Backend Developer| 29|         6| 74000|    [29.0,6.0]|\n",
      "|     Mark Young|    Network Engineer| 32|         9| 81000|    [32.0,9.0]|\n",
      "|     Nancy King|           Recruiter| 28|         5| 67000|    [28.0,5.0]|\n",
      "|    Paul Wright|Database Administ...| 37|        13| 95000|   [37.0,13.0]|\n",
      "|    Karen Scott|     Product Manager| 39|        15|115000|   [39.0,15.0]|\n",
      "|    Steven Hill|      Cloud Engineer| 31|         7| 87000|    [31.0,7.0]|\n",
      "+---------------+--------------------+---+----------+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'designation', 'age', 'experience', 'salary', 'Indep features']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_data=output.select(\"Indep features\",\"salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "train_data,test_data=finalized_data.randomSplit([0.75,0.25])\n",
    "regressor=LinearRegression(featuresCol='Indep features',labelCol='salary')\n",
    "regressor=regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11391.663134089524"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([2615.1759, 1091.9881])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=regressor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+------------------+\n",
      "|Indep features|salary|        prediction|\n",
      "+--------------+------+------------------+\n",
      "|    [26.0,3.0]| 62000|59878.875229617115|\n",
      "|    [29.0,6.0]| 75000| 71000.36738731113|\n",
      "|    [31.0,7.0]| 78000| 77322.70736187635|\n",
      "|   [35.0,10.0]|110000| 91059.37544157093|\n",
      "|   [36.0,12.0]| 92000| 95858.52762469972|\n",
      "+--------------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78918090.14792202,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.meanSquaredError,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5919.440440864841"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.meanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysparkenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
